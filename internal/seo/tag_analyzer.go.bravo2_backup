package seo

import (
	"fmt"
	"regexp"
	"strings"

	"firesalamander/internal/constants"
	"golang.org/x/net/html"
	"golang.org/x/net/html/atom"
)

// TagAnalyzer analyseur de balises SEO spécialisé
type TagAnalyzer struct {
	// Regex pour validation
	titleRegex       *regexp.Regexp
	metaDescRegex    *regexp.Regexp
	urlRegex         *regexp.Regexp
	imageExtRegex    *regexp.Regexp
}

// TagAnalysisResult résultat de l'analyse des balises
type TagAnalysisResult struct {
	Title           TitleAnalysis       `json:"title"`
	MetaDescription MetaDescAnalysis    `json:"meta_description"`
	Headings        HeadingAnalysis     `json:"headings"`
	MetaTags        MetaTagsAnalysis    `json:"meta_tags"`
	Images          ImageAnalysis       `json:"images"`
	Links           LinkAnalysis        `json:"links"`
	Microdata       MicrodataAnalysis   `json:"microdata"`
}

// TitleAnalysis analyse du titre
type TitleAnalysis struct {
	Present          bool     `json:"present"`
	Content          string   `json:"content"`
	Length           int      `json:"length"`
	OptimalLength    bool     `json:"optimal_length"`
	HasKeywords      bool     `json:"has_keywords"`
	DuplicateWords   []string `json:"duplicate_words"`
	Issues           []string `json:"issues"`
	Recommendations  []string `json:"recommendations"`
}

// MetaDescAnalysis analyse de la meta description
type MetaDescAnalysis struct {
	Present          bool     `json:"present"`
	Content          string   `json:"content"`
	Length           int      `json:"length"`
	OptimalLength    bool     `json:"optimal_length"`
	HasCallToAction  bool     `json:"has_call_to_action"`
	Issues           []string `json:"issues"`
	Recommendations  []string `json:"recommendations"`
}

// HeadingAnalysis analyse de la structure des titres
type HeadingAnalysis struct {
	H1Count         int                    `json:"h1_count"`
	H1Content       []string               `json:"h1_content"`
	HeadingStructure map[string][]string   `json:"heading_structure"`
	HasHierarchy    bool                   `json:"has_hierarchy"`
	MissingLevels   []string               `json:"missing_levels"`
	Issues          []string               `json:"issues"`
	Recommendations []string               `json:"recommendations"`
}

// MetaTagsAnalysis analyse des meta tags
type MetaTagsAnalysis struct {
	HasRobots       bool     `json:"has_robots"`
	RobotsContent   string   `json:"robots_content"`
	HasCanonical    bool     `json:"has_canonical"`
	CanonicalURL    string   `json:"canonical_url"`
	HasOGTags       bool     `json:"has_og_tags"`
	OGTags          []OGTag  `json:"og_tags"`
	HasTwitterCard  bool     `json:"has_twitter_card"`
	TwitterCard     []TwitterTag `json:"twitter_card"`
	HasViewport     bool     `json:"has_viewport"`
	ViewportContent string   `json:"viewport_content"`
	Issues          []string `json:"issues"`
	Recommendations []string `json:"recommendations"`
}

// ImageAnalysis analyse des images
type ImageAnalysis struct {
	TotalImages      int      `json:"total_images"`
	ImagesWithAlt    int      `json:"images_with_alt"`
	AltTextCoverage  float64  `json:"alt_text_coverage"`
	MissingAltImages []string `json:"missing_alt_images"`
	OptimizedFormats int      `json:"optimized_formats"`
	LazyLoading      int      `json:"lazy_loading"`
	Issues           []string `json:"issues"`
	Recommendations  []string `json:"recommendations"`
}

// LinkAnalysis analyse des liens
type LinkAnalysis struct {
	InternalLinks    int      `json:"internal_links"`
	ExternalLinks    int      `json:"external_links"`
	NoFollowLinks    int      `json:"nofollow_links"`
	BrokenLinks      int      `json:"broken_links"`
	AnchorOptimization float64 `json:"anchor_optimization"`
	Issues           []string `json:"issues"`
	Recommendations  []string `json:"recommendations"`
}

// MicrodataAnalysis analyse des données structurées
type MicrodataAnalysis struct {
	HasJSONLD        bool     `json:"has_json_ld"`
	JSONLDTypes      []string `json:"json_ld_types"`
	HasMicrodata     bool     `json:"has_microdata"`
	MicrodataTypes   []string `json:"microdata_types"`
	HasRDFa          bool     `json:"has_rdfa"`
	Issues           []string `json:"issues"`
	Recommendations  []string `json:"recommendations"`
}

// OGTag balise Open Graph
type OGTag struct {
	Property string `json:"property"`
	Content  string `json:"content"`
}

// TwitterTag balise Twitter Card
type TwitterTag struct {
	Name    string `json:"name"`
	Content string `json:"content"`
}

// NewTagAnalyzer crée un nouvel analyseur de balises
func NewTagAnalyzer() *TagAnalyzer {
	return &TagAnalyzer{
		titleRegex:    regexp.MustCompile(constants.TagRegexTitlePattern),
		metaDescRegex: regexp.MustCompile(constants.TagRegexMetaDescPattern),
		urlRegex:      regexp.MustCompile(constants.TagRegexURLPattern),
		imageExtRegex: regexp.MustCompile(constants.TagRegexImageExtPattern),
	}
}

// Analyze effectue l'analyse complète des balises SEO
func (ta *TagAnalyzer) Analyze(doc *html.Node, htmlContent string) (*TagAnalysisResult, error) {
	result := &TagAnalysisResult{}

	// Analyse du titre
	result.Title = ta.analyzeTitle(doc)

	// Analyse de la meta description
	result.MetaDescription = ta.analyzeMetaDescription(doc)

	// Analyse des headings
	result.Headings = ta.analyzeHeadings(doc)

	// Analyse des meta tags
	result.MetaTags = ta.analyzeMetaTags(doc)

	// Analyse des images
	result.Images = ta.analyzeImages(doc)

	// Analyse des liens
	result.Links = ta.analyzeLinks(doc)

	// Analyse des données structurées
	result.Microdata = ta.analyzeMicrodata(doc, htmlContent)

	return result, nil
}

// analyzeTitle analyse le titre de la page
func (ta *TagAnalyzer) analyzeTitle(doc *html.Node) TitleAnalysis {
	analysis := TitleAnalysis{
		Issues:          []string{},
		Recommendations: []string{},
	}

	// Trouver la balise title
	titleNode := ta.findNodeByAtom(doc, atom.Title)
	if titleNode == nil || titleNode.FirstChild == nil {
		analysis.Issues = append(analysis.Issues, constants.TagMsgTitleMissing)
		analysis.Recommendations = append(analysis.Recommendations, constants.TagRecommendAddTitle)
		return analysis
	}

	analysis.Present = true
	analysis.Content = strings.TrimSpace(titleNode.FirstChild.Data)
	analysis.Length = len(analysis.Content)

	// Vérifier la longueur optimale (30-60 caractères)
	if analysis.Length >= constants.TagTitleMinLength && analysis.Length <= constants.TagTitleMaxLength {
		analysis.OptimalLength = true
	} else if analysis.Length < constants.TagTitleMinLength {
		analysis.Issues = append(analysis.Issues, constants.TagMsgTitleTooShort)
		analysis.Recommendations = append(analysis.Recommendations, constants.TagRecommendExtendTitle)
	} else {
		analysis.Issues = append(analysis.Issues, constants.TagMsgTitleTooLong)
		analysis.Recommendations = append(analysis.Recommendations, constants.TagRecommendShortenTitle)
	}

	// Détecter les mots dupliqués
	words := strings.Fields(strings.ToLower(analysis.Content))
	wordCount := make(map[string]int)
	for _, word := range words {
		wordCount[word]++
	}
	
	for word, count := range wordCount {
		if count > 1 && len(word) > 3 {
			analysis.DuplicateWords = append(analysis.DuplicateWords, word)
		}
	}

	if len(analysis.DuplicateWords) > 0 {
		analysis.Issues = append(analysis.Issues, constants.TagMsgTitleDuplicates)
		analysis.Recommendations = append(analysis.Recommendations, constants.TagRecommendAvoidDuplicates)
	}

	// Vérifier la présence de mots-clés potentiels
	if len(words) >= constants.TagMinWordLength {
		analysis.HasKeywords = true
	}

	return analysis
}

// analyzeMetaDescription analyse la meta description
func (ta *TagAnalyzer) analyzeMetaDescription(doc *html.Node) MetaDescAnalysis {
	analysis := MetaDescAnalysis{
		Issues:          []string{},
		Recommendations: []string{},
	}

	// Trouver la meta description
	metaDesc := ta.findMetaByName(doc, constants.TagMetaNameDescription)
	if metaDesc == "" {
		analysis.Issues = append(analysis.Issues, constants.TagMsgMetaDescMissing)
		analysis.Recommendations = append(analysis.Recommendations, constants.TagRecommendAddMetaDesc)
		return analysis
	}

	analysis.Present = true
	analysis.Content = metaDesc
	analysis.Length = len(analysis.Content)

	// Vérifier la longueur optimale (120-160 caractères)
	if analysis.Length >= constants.TagMetaDescMinLength && analysis.Length <= constants.TagMetaDescMaxLength {
		analysis.OptimalLength = true
	} else if analysis.Length < constants.TagMetaDescMinLength {
		analysis.Issues = append(analysis.Issues, "Meta description trop courte")
		analysis.Recommendations = append(analysis.Recommendations, "Étendre la meta description (120-160 caractères)")
	} else {
		analysis.Issues = append(analysis.Issues, "Meta description trop longue")
		analysis.Recommendations = append(analysis.Recommendations, "Raccourcir la meta description")
	}

	// Détecter les appels à l'action
	ctas := []string{
		"découvrir", "en savoir plus", "contacter", "commander", "acheter",
		"télécharger", "s'inscrire", "essayer", "commencer", "cliquer",
		"discover", "learn more", "contact", "order", "buy", "download",
		"sign up", "try", "start", "click",
	}

	lowerContent := strings.ToLower(analysis.Content)
	for _, cta := range ctas {
		if strings.Contains(lowerContent, cta) {
			analysis.HasCallToAction = true
			break
		}
	}

	if !analysis.HasCallToAction {
		analysis.Recommendations = append(analysis.Recommendations, "Ajouter un appel à l'action dans la meta description")
	}

	return analysis
}

// analyzeHeadings analyse la structure des titres
func (ta *TagAnalyzer) analyzeHeadings(doc *html.Node) HeadingAnalysis {
	analysis := HeadingAnalysis{
		H1Content:        []string{},
		HeadingStructure: make(map[string][]string),
		Issues:           []string{},
		Recommendations:  []string{},
	}

	// Rechercher tous les headings
	headingLevels := []atom.Atom{atom.H1, atom.H2, atom.H3, atom.H4, atom.H5, atom.H6}
	levelNames := []string{"h1", "h2", "h3", "h4", "h5", "h6"}

	for i, level := range headingLevels {
		levelName := levelNames[i]
		headings := ta.findAllNodesByAtom(doc, level)
		
		for _, heading := range headings {
			text := ta.extractTextContent(heading)
			if text != "" {
				analysis.HeadingStructure[levelName] = append(analysis.HeadingStructure[levelName], text)
				
				if level == atom.H1 {
					analysis.H1Content = append(analysis.H1Content, text)
				}
			}
		}
	}

	analysis.H1Count = len(analysis.H1Content)

	// Vérifications
	if analysis.H1Count == 0 {
		analysis.Issues = append(analysis.Issues, "Aucun titre H1")
		analysis.Recommendations = append(analysis.Recommendations, "Ajouter un titre H1 principal")
	} else if analysis.H1Count > 1 {
		analysis.Issues = append(analysis.Issues, "Plusieurs titres H1")
		analysis.Recommendations = append(analysis.Recommendations, "Utiliser un seul H1 par page")
	}

	// Vérifier la hiérarchie
	analysis.HasHierarchy = ta.checkHeadingHierarchy(analysis.HeadingStructure)
	if !analysis.HasHierarchy {
		analysis.Issues = append(analysis.Issues, "Hiérarchie des titres incorrecte")
		analysis.Recommendations = append(analysis.Recommendations, "Respecter la hiérarchie H1 > H2 > H3...")
	}

	return analysis
}

// analyzeMetaTags analyse les meta tags
func (ta *TagAnalyzer) analyzeMetaTags(doc *html.Node) MetaTagsAnalysis {
	analysis := MetaTagsAnalysis{
		OGTags:          []OGTag{},
		TwitterCard:     []TwitterTag{},
		Issues:          []string{},
		Recommendations: []string{},
	}

	// Meta robots
	robots := ta.findMetaByName(doc, "robots")
	if robots != "" {
		analysis.HasRobots = true
		analysis.RobotsContent = robots
	}

	// Canonical URL
	canonical := ta.findLinkByRel(doc, "canonical")
	if canonical != "" {
		analysis.HasCanonical = true
		analysis.CanonicalURL = canonical
	} else {
		analysis.Recommendations = append(analysis.Recommendations, "Ajouter une URL canonique")
	}

	// Viewport
	viewport := ta.findMetaByName(doc, "viewport")
	if viewport != "" {
		analysis.HasViewport = true
		analysis.ViewportContent = viewport
	} else {
		analysis.Issues = append(analysis.Issues, "Meta viewport manquante")
		analysis.Recommendations = append(analysis.Recommendations, "Ajouter meta viewport pour le responsive")
	}

	// Open Graph tags
	ogTags := ta.findAllMetaByProperty(doc, "og:")
	if len(ogTags) > 0 {
		analysis.HasOGTags = true
		for property, content := range ogTags {
			analysis.OGTags = append(analysis.OGTags, OGTag{
				Property: property,
				Content:  content,
			})
		}
	} else {
		analysis.Recommendations = append(analysis.Recommendations, "Ajouter les balises Open Graph")
	}

	// Twitter Card
	twitterTags := ta.findAllMetaByName(doc, "twitter:")
	if len(twitterTags) > 0 {
		analysis.HasTwitterCard = true
		for name, content := range twitterTags {
			analysis.TwitterCard = append(analysis.TwitterCard, TwitterTag{
				Name:    name,
				Content: content,
			})
		}
	} else {
		analysis.Recommendations = append(analysis.Recommendations, "Ajouter les balises Twitter Card")
	}

	return analysis
}

// analyzeImages analyse les images
func (ta *TagAnalyzer) analyzeImages(doc *html.Node) ImageAnalysis {
	analysis := ImageAnalysis{
		MissingAltImages: []string{},
		Issues:           []string{},
		Recommendations:  []string{},
	}

	images := ta.findAllNodesByAtom(doc, atom.Img)
	analysis.TotalImages = len(images)

	if analysis.TotalImages == 0 {
		return analysis
	}

	for _, img := range images {
		src := ta.getAttr(img, "src")
		alt := ta.getAttr(img, "alt")
		loading := ta.getAttr(img, "loading")

		if alt != "" {
			analysis.ImagesWithAlt++
		} else {
			analysis.MissingAltImages = append(analysis.MissingAltImages, src)
		}

		// Vérifier le format optimisé
		if ta.imageExtRegex.MatchString(strings.ToLower(src)) {
			analysis.OptimizedFormats++
		}

		// Vérifier le lazy loading
		if loading == "lazy" {
			analysis.LazyLoading++
		}
	}

	analysis.AltTextCoverage = float64(analysis.ImagesWithAlt) / float64(analysis.TotalImages)

	// Recommandations
	if analysis.AltTextCoverage < 1.0 {
		analysis.Issues = append(analysis.Issues, fmt.Sprintf("%d images sans texte alternatif", len(analysis.MissingAltImages)))
		analysis.Recommendations = append(analysis.Recommendations, "Ajouter des textes alternatifs à toutes les images")
	}

	if analysis.LazyLoading < analysis.TotalImages {
		analysis.Recommendations = append(analysis.Recommendations, "Implémenter le lazy loading pour les images")
	}

	return analysis
}

// analyzeLinks analyse les liens
func (ta *TagAnalyzer) analyzeLinks(doc *html.Node) LinkAnalysis {
	analysis := LinkAnalysis{
		Issues:          []string{},
		Recommendations: []string{},
	}

	links := ta.findAllNodesByAtom(doc, atom.A)
	goodAnchors := 0
	badAnchors := []string{"cliquez ici", "click here", "lire la suite", "read more", "ici", "here"}

	for _, link := range links {
		href := ta.getAttr(link, "href")
		rel := ta.getAttr(link, "rel")
		text := ta.extractTextContent(link)

		if href == "" {
			continue
		}

		// Classifier les liens
		if strings.HasPrefix(href, "http") {
			analysis.ExternalLinks++
		} else if strings.HasPrefix(href, "/") || !strings.Contains(href, "://") {
			analysis.InternalLinks++
		}

		// Vérifier nofollow
		if strings.Contains(rel, "nofollow") {
			analysis.NoFollowLinks++
		}

		// Évaluer la qualité de l'ancre
		isGoodAnchor := true
		lowerText := strings.ToLower(text)
		
		for _, badAnchor := range badAnchors {
			if strings.Contains(lowerText, badAnchor) {
				isGoodAnchor = false
				break
			}
		}

		if isGoodAnchor && len(text) > 3 {
			goodAnchors++
		}
	}

	totalLinks := analysis.InternalLinks + analysis.ExternalLinks
	if totalLinks > 0 {
		analysis.AnchorOptimization = float64(goodAnchors) / float64(totalLinks)
	}

	// Recommandations
	if analysis.InternalLinks < 3 {
		analysis.Recommendations = append(analysis.Recommendations, "Améliorer le maillage interne")
	}

	if analysis.AnchorOptimization < 0.7 {
		analysis.Issues = append(analysis.Issues, "Textes d'ancre peu optimisés")
		analysis.Recommendations = append(analysis.Recommendations, "Optimiser les textes d'ancres des liens")
	}

	return analysis
}

// analyzeMicrodata analyse les données structurées
func (ta *TagAnalyzer) analyzeMicrodata(doc *html.Node, htmlContent string) MicrodataAnalysis {
	analysis := MicrodataAnalysis{
		JSONLDTypes:     []string{},
		MicrodataTypes:  []string{},
		Issues:          []string{},
		Recommendations: []string{},
	}

	// Rechercher JSON-LD
	scripts := ta.findAllNodesByAtom(doc, atom.Script)
	for _, script := range scripts {
		scriptType := ta.getAttr(script, "type")
		if scriptType == "application/ld+json" {
			analysis.HasJSONLD = true
			// Ici on pourrait parser le JSON pour extraire les types
			analysis.JSONLDTypes = append(analysis.JSONLDTypes, "detected")
		}
	}

	// Rechercher microdata
	if strings.Contains(htmlContent, "itemscope") {
		analysis.HasMicrodata = true
	}

	// Rechercher RDFa
	if strings.Contains(htmlContent, "typeof") || strings.Contains(htmlContent, "vocab") {
		analysis.HasRDFa = true
	}

	// Recommandations
	if !analysis.HasJSONLD && !analysis.HasMicrodata && !analysis.HasRDFa {
		analysis.Recommendations = append(analysis.Recommendations, "Ajouter des données structurées (JSON-LD recommandé)")
	}

	return analysis
}

// Fonctions utilitaires

func (ta *TagAnalyzer) findNodeByAtom(doc *html.Node, targetAtom atom.Atom) *html.Node {
	var result *html.Node
	ta.walkHTML(doc, func(n *html.Node) {
		if result == nil && n.DataAtom == targetAtom {
			result = n
		}
	})
	return result
}

func (ta *TagAnalyzer) findAllNodesByAtom(doc *html.Node, targetAtom atom.Atom) []*html.Node {
	var results []*html.Node
	ta.walkHTML(doc, func(n *html.Node) {
		if n.DataAtom == targetAtom {
			results = append(results, n)
		}
	})
	return results
}

func (ta *TagAnalyzer) findMetaByName(doc *html.Node, name string) string {
	var content string
	ta.walkHTML(doc, func(n *html.Node) {
		if n.DataAtom == atom.Meta {
			nameAttr := ta.getAttr(n, "name")
			if nameAttr == name {
				content = ta.getAttr(n, "content")
			}
		}
	})
	return content
}

func (ta *TagAnalyzer) findLinkByRel(doc *html.Node, rel string) string {
	var href string
	ta.walkHTML(doc, func(n *html.Node) {
		if n.DataAtom == atom.Link {
			relAttr := ta.getAttr(n, "rel")
			if relAttr == rel {
				href = ta.getAttr(n, "href")
			}
		}
	})
	return href
}

func (ta *TagAnalyzer) findAllMetaByProperty(doc *html.Node, prefix string) map[string]string {
	results := make(map[string]string)
	ta.walkHTML(doc, func(n *html.Node) {
		if n.DataAtom == atom.Meta {
			property := ta.getAttr(n, "property")
			if strings.HasPrefix(property, prefix) {
				content := ta.getAttr(n, "content")
				results[property] = content
			}
		}
	})
	return results
}

func (ta *TagAnalyzer) findAllMetaByName(doc *html.Node, prefix string) map[string]string {
	results := make(map[string]string)
	ta.walkHTML(doc, func(n *html.Node) {
		if n.DataAtom == atom.Meta {
			name := ta.getAttr(n, "name")
			if strings.HasPrefix(name, prefix) {
				content := ta.getAttr(n, "content")
				results[name] = content
			}
		}
	})
	return results
}

func (ta *TagAnalyzer) checkHeadingHierarchy(structure map[string][]string) bool {
	// Vérifier qu'il y a un H1 et au moins un H2
	h1Count := len(structure["h1"])
	h2Count := len(structure["h2"])
	
	return h1Count == 1 && h2Count >= 1
}

func (ta *TagAnalyzer) walkHTML(n *html.Node, fn func(*html.Node)) {
	fn(n)
	for c := n.FirstChild; c != nil; c = c.NextSibling {
		ta.walkHTML(c, fn)
	}
}

func (ta *TagAnalyzer) getAttr(n *html.Node, key string) string {
	for _, attr := range n.Attr {
		if attr.Key == key {
			return attr.Val
		}
	}
	return ""
}

func (ta *TagAnalyzer) extractTextContent(n *html.Node) string {
	var texts []string
	ta.walkHTML(n, func(child *html.Node) {
		if child.Type == html.TextNode {
			text := strings.TrimSpace(child.Data)
			if text != "" {
				texts = append(texts, text)
			}
		}
	})
	return strings.Join(texts, " ")
}