package crawler

import (
	"context"

	"firesalamander/internal/config"
)

// IntelligentAdapter adapte le crawler intelligent pour l'interface ParallelCrawler existante
// 
// Cette structure permet l'int√©gration transparente du crawler intelligent avec cleanHTML()
// dans le code existant sans breaking changes, respectant le principe Open/Closed de SOLID.
//
// Avantages:
// - Compatible 100% avec interface ParallelCrawler
// - Injection automatique de cleanHTML() pour r√©soudre caract√®res HTML invalides  
// - Performance am√©lior√©e vs timeouts 90s
// - Facilit√© de rollback si n√©cessaire
type IntelligentAdapter struct {
	intelligentCrawler ICrawlerEngine // Crawler intelligent avec cleanHTML int√©gr√©
}

// NewIntelligentAdapter cr√©e un nouvel adaptateur utilisant le crawler intelligent avec cleanHTML
func NewIntelligentAdapter(cfg *config.CrawlerConfig) *IntelligentAdapter {
	return &IntelligentAdapter{
		intelligentCrawler: NewIntelligentCrawler(cfg),
	}
}

// CrawlWithContext adapte CrawlWithIntelligence vers l'interface ParallelCrawler existante
//
// Cette m√©thode maintient la signature compatible avec l'orchestrator existant
// tout en utilisant le crawler intelligent avec cleanHTML() automatiquement appliqu√©.
//
// R√©sout le probl√®me des caract√®res HTML invalides qui causaient des timeouts 90s
// sur des sites comme septeo.com, resalys.com, etc.
func (ia *IntelligentAdapter) CrawlWithContext(ctx context.Context, url string) (*ParallelCrawlResult, error) {
	// Phase 1: Utiliser le crawler intelligent avec cleanHTML int√©gr√©
	log.Info("üîç IntelligentAdapter: Starting CrawlWithIntelligence", map[string]interface{}{"url": url})
	intelligentResult, err := ia.intelligentCrawler.CrawlWithIntelligence(ctx, url)
	if err != nil {
		return &ParallelCrawlResult{
			StartURL: url,
			Error:    err,
		}, err
	}

	// Phase 2: Adapter le r√©sultat vers ParallelCrawlResult pour compatibilit√© totale
	// Les pages sont d√©j√† nettoy√©es par cleanHTML() dans CrawlWithIntelligence()
	log.Info("üîç IntelligentAdapter: Got pages from CrawlWithIntelligence", map[string]interface{}{"pages_count": len(intelligentResult.Pages)})
	adaptedResult := &ParallelCrawlResult{
		StartURL: intelligentResult.StartURL,
		Pages:    intelligentResult.Pages, // ‚úÖ Pages avec cleanHTML appliqu√©
		Duration: intelligentResult.Duration,
		Metrics:  intelligentResult.Metrics,
		Error:    intelligentResult.Error,
	}

	return adaptedResult, nil
}