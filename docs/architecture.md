# Architecture Fire Salamander

## Vue d'ensemble

Fire Salamander est un systÃ¨me d'audit SEO automatisÃ© dÃ©veloppÃ© pour SEPTEO Digital Services, conÃ§u pour remplacer les solutions payantes comme Screaming Frog.

## SchÃ©ma du systÃ¨me

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[["ğŸ–¥ï¸ Interface Web<br/>HTML/CSS/JS<br/>Templates SEPTEO"]]
    end
    
    subgraph "Orchestration Layer"
        ORCH[["ğŸ¯ Orchestrator<br/>Go - JSON-RPC<br/>Audit ID: FS-XXX"]]
    end
    
    subgraph "Processing Layer"
        CRAWL[["ğŸ•·ï¸ Crawler<br/>Go - BFS<br/>300 pages max"]]
        TECH[["ğŸ”§ Technical<br/>Go - Lighthouse<br/>SEO/Perf/A11y"]]
        SEM[["ğŸ§  Semantic<br/>Python - NLP<br/>CamemBERT"]]
    end
    
    subgraph "Data Layer"
        JSON1[(crawl_index.json)]
        JSON2[(tech_result.json)]
        JSON3[(semantic_result.json)]
        CONFIG[(config/*.yaml)]
    end
    
    subgraph "Output Layer"
        REPORT[["ğŸ“Š Report Engine<br/>Go - PDF/HTML<br/>Puppeteer"]]
        PDF[["ğŸ“„ Rapport PDF<br/>Scores + Suggestions"]]
    end
    
    subgraph "Legend"
        L1["ğŸŸª Composants back-end"]
        L2["ğŸŸ¦ Interface utilisateur"]
        L3["ğŸŸ¨ Couches logiques"]
        L4["ğŸŸ¢ DonnÃ©es (JSON/YAML)"]
    end
    
    UI -->|"POST /audit"| ORCH
    ORCH -->|"start_crawl"| CRAWL
    ORCH -->|"analyze"| TECH
    ORCH -->|"extract"| SEM
    
    CRAWL -->|"pages data"| JSON1
    TECH -->|"scores"| JSON2
    SEM -->|"keywords"| JSON3
    
    JSON1 --> TECH
    JSON1 --> SEM
    
    JSON1 --> REPORT
    JSON2 --> REPORT
    JSON3 --> REPORT
    CONFIG -.->|"read"| CRAWL
    CONFIG -.->|"read"| TECH
    CONFIG -.->|"read"| SEM
    
    REPORT --> PDF
    PDF -->|"download"| UI
    
    style UI fill:#e1f5fe
    style ORCH fill:#fff3e0
    style CRAWL fill:#f3e5f5
    style TECH fill:#f3e5f5
    style SEM fill:#f3e5f5
    style REPORT fill:#e8f5e9
    style PDF fill:#c8e6c9
    style JSON1 fill:#c8e6c9
    style JSON2 fill:#c8e6c9
    style JSON3 fill:#c8e6c9
    style CONFIG fill:#c8e6c9
    
    style L1 fill:#f3e5f5
    style L2 fill:#e1f5fe
    style L3 fill:#fff3e0
    style L4 fill:#c8e6c9
```

## Description des composants

### Frontend Layer (ğŸŸ¦ Interface utilisateur)

**Interface Web** : Application web utilisant les templates SEPTEO
- Technologies : HTML5, CSS3, JavaScript vanilla
- ResponsabilitÃ©s :
  - Saisie de l'URL Ã  auditer
  - Affichage de la progression
  - TÃ©lÃ©chargement du rapport

### Orchestration Layer (ğŸŸ¨ Couches logiques)

**Orchestrator** : Service de coordination central
- Technologies : Go, JSON-RPC 2.0
- ResponsabilitÃ©s :
  - GÃ©nÃ©ration des audit_id (format FS-XXX)
  - Coordination des agents
  - Gestion des Ã©tats d'audit
  - Communication asynchrone

### Processing Layer (ğŸŸª Composants back-end)

#### Crawler Agent
- **Technologie** : Go
- **Algorithme** : BFS (Breadth-First Search)
- **Limites** :
  - Max 300 pages
  - Profondeur max : 3
  - Timeout : 5 minutes
- **Respect** : robots.txt, sitemap.xml

#### Technical Analyzer
- **Technologie** : Go + Google Lighthouse
- **Analyses** :
  - SEO : meta tags, headings, structure
  - Performance : Core Web Vitals
  - AccessibilitÃ© : WCAG 2.1
  - Best Practices : HTTPS, console errors

#### Semantic Analyzer
- **Technologie** : Python
- **ML/NLP** :
  - ModÃ¨le : CamemBERT/DistilCamemBERT
  - Extraction : N-grammes (2-5 mots)
  - Clustering : HDBSCAN
  - Ranking : XGBoost

### Data Layer (ğŸŸ¢ DonnÃ©es)

- **Formats** : JSON pour les donnÃ©es, YAML pour la configuration
- **Stockage** : SystÃ¨me de fichiers local
- **Structure** : `/audits/{audit_id}/`
- **RÃ©tention** : 30 jours

### Output Layer

**Report Engine** : GÃ©nÃ©ration de rapports
- Technologies : Go + Puppeteer/wkhtmltopdf
- Formats : PDF et HTML
- Contenu :
  - Executive summary
  - Scores techniques
  - Suggestions sÃ©mantiques
  - Recommandations priorisÃ©es

## Flux de donnÃ©es

1. **Initiation** : L'utilisateur entre une URL via l'interface web
2. **Orchestration** : L'orchestrator gÃ©nÃ¨re un audit_id unique
3. **Crawling** : Le crawler explore le site en respectant les contraintes
4. **Analyse parallÃ¨le** : Technical et Semantic analysent les donnÃ©es
5. **AgrÃ©gation** : Les rÃ©sultats JSON sont consolidÃ©s
6. **Rapport** : Generation du PDF avec tous les insights
7. **Livraison** : Le rapport est disponible au tÃ©lÃ©chargement

## Communication inter-agents

**Protocole** : JSON-RPC 2.0

**Exemple de message** :
```json
{
  "jsonrpc": "2.0",
  "method": "start_crawl",
  "params": {
    "audit_id": "FS-001",
    "seed_url": "https://example.fr",
    "max_urls": 300
  },
  "id": "orch-001"
}
```

## MÃ©triques de performance

| Composant | MÃ©trique | Cible |
|-----------|----------|-------|
| Crawler | Pages/seconde | > 2 |
| Technical | Analyse/page | < 2s |
| Semantic | Traitement total | < 60s |
| Report | GÃ©nÃ©ration PDF | < 30s |
| **Total** | **Audit complet** | **< 5 min** |

## Technologies et dÃ©pendances

### Backend (Go)
- **Version** : Go 1.21+
- **Frameworks** :
  - Gorilla Mux (routing)
  - Colly (crawling)
  - Testify (tests)
- **IntÃ©grations** :
  - Google Lighthouse API
  - Puppeteer (via subprocess)

### ML/NLP (Python)
- **Version** : Python 3.9+
- **Frameworks** :
  - Flask (API REST)
  - Transformers (HuggingFace)
  - scikit-learn (clustering)
- **ModÃ¨les** :
  - CamemBERT-base (production)
  - DistilCamemBERT (mode rapide)

### Configuration
- **Crawler** : `config/crawler.yaml`
- **Technical** : `config/tech_rules.yaml`
- **Semantic** : `config/semantic.yaml`
- **Stopwords** : `config/stopwords_fr.txt`

## Gestion des erreurs

### StratÃ©gies de fallback
1. **Crawler fails** â†’ Rapport "Site inaccessible"
2. **Technical fails** â†’ Analyse basique (titre/meta)
3. **Semantic fails** â†’ Keywords par regex simple
4. **Report fails** â†’ Export JSON brut

### Circuit breaker
- Seuil d'Ã©chec : 5 erreurs consÃ©cutives
- Temps de recovery : 60 secondes
- Mode dÃ©gradÃ© : Service partiel maintenu

## SÃ©curitÃ©

### Mesures implÃ©mentÃ©es
- Rate limiting : 2 req/s par dÃ©faut
- Validation d'entrÃ©e : URL whitelist
- Timeout stricts : PrÃ©vention DoS
- Sandboxing : Isolation des analyses

### RGPD et conformitÃ©
- Pas de stockage de donnÃ©es personnelles
- RÃ©tention limitÃ©e (30 jours)
- Logs anonymisÃ©s
- Droit Ã  l'effacement

## Ã‰volutions futures

### Phase 2 - FonctionnalitÃ©s avancÃ©es
- Support multi-langues (EN, ES, IT)
- Analyse concurrentielle
- Tracking historique des changements
- API publique documentÃ©e

### Phase 3 - Intelligence artificielle
- Suggestions de contenu par GPT
- PrÃ©diction de trafic
- DÃ©tection d'anomalies
- Recommandations personnalisÃ©es