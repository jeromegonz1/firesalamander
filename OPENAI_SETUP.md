# ü§ñ Configuration OpenAI pour Fire Salamander

## Vue d'ensemble

Fire Salamander utilise un **syst√®me hybride** pour l'analyse s√©mantique :
- **Analyse locale** (gratuite) : N-grammes, TF-IDF, scoring basique
- **Enrichissement IA** (payant) : Questions de contenu, intentions de recherche, recommandations avanc√©es

L'IA n'est appel√©e que lorsque l'analyse locale n'est pas suffisamment confiante (< 80%), ce qui limite les co√ªts √† ~2‚Ç¨/mois.

## üîë Obtenir une cl√© API OpenAI

1. **Cr√©er un compte OpenAI** : https://platform.openai.com/signup
2. **Ajouter un moyen de paiement** : Billing & Payment methods
3. **G√©n√©rer une cl√© API** : API Keys ‚Üí Create new secret key
4. **Copier la cl√©** : Format `sk-...` (gardez-la secr√®te !)

## üìù Configuration de Fire Salamander

### √âtape 1 : Cr√©er le fichier .env

```bash
# Copier le template
cp .env.example .env

# √âditer le fichier .env
nano .env
```

### √âtape 2 : Ajouter votre cl√© API

```bash
# Fire Salamander - Variables d'environnement

# Configuration OpenAI
OPENAI_API_KEY=sk-votre-vraie-cle-api-ici

# Configuration de base de donn√©es (production)
DB_NAME=firesalamander
DB_USER=your_db_user
DB_PASS=your_db_password
```

### √âtape 3 : V√©rifier la configuration

```bash
# D√©marrer Fire Salamander
./fire-salamander-web

# Tester une analyse
curl -X POST http://localhost:3000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

## üéØ Fonctionnement du syst√®me hybride

### Workflow d'analyse

```mermaid
graph TD
    A[Contenu HTML] --> B[Extraction locale]
    B --> C[Analyse N-grammes + TF-IDF]
    C --> D{Confiance > 80% ?}
    D -->|Oui| E[R√©sultat final]
    D -->|Non| F[Enrichissement OpenAI]
    F --> G[Cache 1h]
    G --> E
```

### √âconomies r√©alis√©es

- **Analyse locale** : 100% gratuite
- **IA s√©lective** : Seulement si n√©cessaire
- **Cache intelligent** : 1h en dev, 2h en prod
- **Limitation tokens** : 800-1000 tokens max
- **Mod√®le √©conomique** : GPT-3.5-turbo (~2‚Ç¨/mois)

## ‚öôÔ∏è Configuration avanc√©e

### Mode d√©veloppement (config.dev.yaml)

```yaml
ai:
  enabled: true
  mock_mode: false  # false = vraie API
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-3.5-turbo"
  max_tokens: 1000
  timeout: 30
  use_cache: true
  cache_ttl: 3600  # 1 heure
```

### Mode production (config.prod.yaml)

```yaml
ai:
  enabled: true
  mock_mode: false
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-3.5-turbo"
  max_tokens: 800    # Moins de tokens = moins cher
  timeout: 30
  use_cache: true
  cache_ttl: 7200    # 2 heures de cache
```

## üîç Types d'enrichissement IA

### 1. Enrichissement des mots-cl√©s
- **Intention de recherche** : informational, transactional, navigational
- **Difficult√©** : Score 1-100 bas√© sur la comp√©titivit√©
- **Volume de recherche** : Estimation low/medium/high
- **Mots-cl√©s associ√©s** : Suggestions s√©mantiquement li√©es

### 2. Questions de contenu
- Questions que se posent les utilisateurs
- Optimisation pour les Featured Snippets
- Am√©lioration de l'intention utilisateur

### 3. Recommandations SEO
- Actions prioritaires d'optimisation
- Opportunit√©s de contenu
- Suggestions d'am√©lioration technique

## üí∞ Estimation des co√ªts

### Usage typique (50 analyses/mois)
- **Analyses sans IA** : 35 (70%) = 0‚Ç¨
- **Analyses avec IA** : 15 (30%) = ~2‚Ç¨
- **Cache hits** : 40% d'√©conomies suppl√©mentaires

### Contr√¥les de co√ªts
- Limitation √† 5 mots-cl√©s max par analyse
- Batch processing pour optimiser
- Cache agressif (1-2h)
- Mod√®le √©conomique (gpt-3.5-turbo)

## üö® Modes de fonctionnement

### Mock Mode (tests)
```yaml
ai:
  enabled: true
  mock_mode: true  # Donn√©es fictives, 0‚Ç¨
```

### Production Mode
```yaml
ai:
  enabled: true
  mock_mode: false  # Vraie API OpenAI
```

### Disabled Mode
```yaml
ai:
  enabled: false  # Analyse locale uniquement
```

## üîß D√©pannage

### Erreur "OpenAI API key not configured"
```bash
# V√©rifier la variable d'environnement
echo $OPENAI_API_KEY

# Red√©marrer avec la variable
export OPENAI_API_KEY=sk-your-key
./fire-salamander-web
```

### Erreur "API returned status 401"
- V√©rifier que la cl√© API est valide
- S'assurer que le billing est configur√© sur OpenAI
- V√©rifier les limites de quota

### Mode fallback
En cas d'erreur OpenAI, Fire Salamander passe automatiquement en mode local avec des donn√©es mock, garantissant un fonctionnement continu.

## üìä Monitoring des co√ªts

### Dashboard interne
- Nombre d'appels IA vs locaux
- Cache hit rate
- Co√ªt estim√© mensuel
- Tokens consomm√©s

### Endpoint de stats
```bash
curl http://localhost:3000/api/v1/stats
```

Retourne les m√©triques d'usage IA et les √©conomies r√©alis√©es.

---

ü¶é **Fire Salamander** - L'IA au service du SEO, ma√Ætris√©e et √©conomique !